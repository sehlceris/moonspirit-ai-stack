version: 1.2.8
cache: true

endpoints:
  # Disable the default OpenAI endpoint (prevents sending keys to OpenAI)
  openAI:
    disabled: true

  # Custom endpoints for local and external providers
  custom:
    # LM Studio - Local LLM server
    - name: "LM Studio"
      apiKey: "sk-lm-missing-key"
      baseURL: "http://host.docker.internal:1234/v1"
      models:
        default: ["local-model"]
        fetch: true
      titleConvo: true
      titleModel: "current_model"
      summarize: false
      dropParams: ["stop"]
      iconURL: "https://lmstudio.ai/favicon.ico"

# Web search configuration using SearXNG
webSearch:
  searchProvider: "searxng"
  searxngInstanceUrl: "http://searxng:8080"
  safeSearch: 0
