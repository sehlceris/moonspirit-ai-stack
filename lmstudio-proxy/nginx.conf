# Nginx configuration for proxying to host's LM Studio
# This allows Docker containers to reach the LLM running on the host

worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /tmp/nginx.pid;

events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    sendfile on;
    keepalive_timeout 65;

    # Upstream to host's LM Studio
    upstream lmstudio {
        server host.docker.internal:1234;
        keepalive 32;
    }

    server {
        listen 80;
        server_name _;

        # Health check endpoint
        location /health {
            return 200 'OK';
            add_header Content-Type text/plain;
        }

        # Proxy all requests to LM Studio on the host
        location / {
            proxy_pass http://lmstudio;
            proxy_http_version 1.1;

            # Headers for WebSocket support (if needed)
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";

            # Standard proxy headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Timeout settings for long-running LLM requests
            proxy_connect_timeout 300s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;

            # Buffering settings
            proxy_buffering off;
            proxy_request_buffering off;

            # Allow large request bodies for context
            client_max_body_size 100M;
        }
    }
}
