# ===========================================
# AI Stack Environment Configuration
# ===========================================
# Copy this file to .env and fill in the values
#
#   cp .env.example .env
#

# ---------------------------------------------
# Basic Authentication (for external access)
# ---------------------------------------------
# Generate with: htpasswd -nB username
# Or with Docker: docker run --rm httpd:alpine htpasswd -nB admin
# The output format is: username:$2y$...hashed_password
TRAEFIK_BASIC_AUTH_USERS=admin:$2y$05$xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ---------------------------------------------
# Cloudflare Tunnel
# ---------------------------------------------
# Your Cloudflare Tunnel token from the Zero Trust dashboard
# Get this from: https://one.dash.cloudflare.com/ -> Networks -> Tunnels
# Create a tunnel and copy the token (starts with eyJ...)
CLOUDFLARE_TUNNEL_TOKEN=eyJhIjoixxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ---------------------------------------------
# OpenWebUI Settings
# ---------------------------------------------
# API key for the local LLM (usually not required for local LM Studio)
OPENAI_API_KEY=sk-no-key-required

# Enable/disable OpenWebUI's built-in authentication (true/false)
OPENWEBUI_AUTH=true

# Display name for the OpenWebUI instance
OPENWEBUI_NAME=AI Stack

# ---------------------------------------------
# External Access Middleware
# ---------------------------------------------
# Controls what middleware is applied to external routes
#
# With basic auth (default):
EXTERNAL_MIDDLEWARES=auth@file
#
# Without basic auth (once you have API tokens set up):
# EXTERNAL_MIDDLEWARES=noauth@file
